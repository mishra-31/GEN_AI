{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Packages are Installed\n"
     ]
    }
   ],
   "source": [
    "# Check if All required packages are installed, \n",
    "# If not, install them\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "# The List of required packages\n",
    "# If an import requires a package to be installed, it Must be in this list, or the End User will have issues\n",
    "required_packages = {'tk', 'pillow', 'pathlib2', 'rasterio', 'openai','pyperclip', 'google-api-python-client', 'google-cloud', \\\n",
    "                     'google-cloud-aiplatform', 'google-cloud-vision'}# Get the list of Installed Packages\n",
    "installed_packages = {package.key for package in pkg_resources.working_set}\n",
    "# Get a list of all the Required Packages that are not Installed\n",
    "missing_packages = required_packages - installed_packages\n",
    "\n",
    "# If Missing packages is not Empty\n",
    "if missing_packages:\n",
    "    # Print the list of Missing Packages\n",
    "    print (\"Missing: \",missing_packages)\n",
    "    # Create an System Excecutable object that allows calling 'pip install <package>'\n",
    "    python_installer = sys.executable\n",
    "    # Itterate through Missing packages and Install them\n",
    "    # Note: Some Imports come from Packages that do not share the same name.\n",
    "    #   - Those Packages are noted below above the Import that they belong to\n",
    "    for pkg in missing_packages:\n",
    "        try:\n",
    "            print(\"Installing: \", pkg)\n",
    "            # Install the Current Package\n",
    "            subprocess.check_call([python_installer, '-m', 'pip', 'install', pkg, '-q'], stdout=subprocess.DEVNULL)\n",
    "            # Print the Installed Package, on a Failure, an Error will occor.\n",
    "            print(\"Installed: \", pkg)\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(\"Could not Install: \", pkg)\n",
    "else:\n",
    "    print(\"All Packages are Installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install tk\n",
    "from tkinter import *\n",
    "from tkinter import ttk, StringVar, font\n",
    "# install pillow\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "from os import getcwd\n",
    "from os.path import isfile, join, abspath\n",
    "import io\n",
    "from pathlib import Path\n",
    "from rasterio.plot import reshape_as_image\n",
    "import rasterio.mask\n",
    "from rasterio.features import rasterize\n",
    "import openai\n",
    "import urllib\n",
    "import pprint\n",
    "#import cv2\n",
    "import json\n",
    "import pyperclip\n",
    "from google.cloud import aiplatform,vision\n",
    "from vertexai.preview.language_models import CodeGenerationModel\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the CWD. This will be used as a Master Refference for everything else\n",
    "directoryPath = abspath(getcwd())\n",
    "# OpenAI model details\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://financial-poc-capegmini.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-03-15-preview\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"147fa51fedb346babf30e8e91b0ad8e5\"\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai.api_type = os.environ[\"OPENAI_API_TYPE\"]\n",
    "openai.api_base = os.environ[\"OPENAI_API_BASE\"]\n",
    "openai.api_version = os.environ[\"OPENAI_API_VERSION\"]\n",
    "\n",
    "# GCP API\n",
    "starchat_URL = 'https://w58yxognl8.execute-api.us-east-1.amazonaws.com/V2/starchat-beta'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_modelA_textbox = None\n",
    "prompt_modelB_textbox = None\n",
    "prompt_textbox = None\n",
    "expected2_textbox = None\n",
    "expected3_textbox = None\n",
    "time2_md_textBox = None\n",
    "time3_md_textBox = None\n",
    "o_response1_textbox = None\n",
    "o_response2_textbox = None\n",
    "s_response1_textbox = None\n",
    "s_response2_textbox = None\n",
    "root = None\n",
    "choice_var = None\n",
    "save_response_button = None\n",
    "modelA_API = \"Default A\\n\"\n",
    "modelB_API = \"Default B\\n\"\n",
    "title_font =('Segoe UI',12)\n",
    "save_default_str = \"Save Review\"\n",
    "#{'family': 'Segoe UI', 'size': 9, 'weight': 'normal', 'slant': 'roman', 'underline': 0, 'overstrike': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_root():\n",
    "    root.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_model_A():\n",
    "    pyperclip.copy(prompt_modelA_textbox.get(\"1.0\",\"end-1c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_model_B():\n",
    "    pyperclip.copy(prompt_modelB_textbox.get(\"1.0\",\"end-1c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model_A():\n",
    "    output_file = open(\"model_a_test.py\",\"w\")\n",
    "    output_file.write(prompt_modelA_textbox.get(\"1.0\",\"end-1c\"))\n",
    "    output_file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model_B():\n",
    "    output_file = open(\"model_b_test.py\",\"w\")\n",
    "    output_file.write(prompt_modelB_textbox.get(\"1.0\",\"end-1c\"))\n",
    "    output_file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model_OpenAI(code):\n",
    "    model_API = \"# OpenAI\\n\"\n",
    "    print(\"Model {code}:\")\n",
    "    print(\"API KEY: \" , os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt_textbox.get(1.0, \"end-1c\"),\n",
    "        temperature=.1,\n",
    "        max_tokens=1000,\n",
    "        top_p=0.1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        best_of=1,\n",
    "        n=1,\n",
    "        stop=None)\n",
    "    if code == \"A\":\n",
    "        prompt_modelA_textbox.delete(\"1.0\",\"end\")\n",
    "        prompt_modelA_textbox.insert(\"end\",model_API + response.choices[0].text)\n",
    "    elif code == \"B\":\n",
    "        prompt_modelB_textbox.delete(\"1.0\",\"end\")\n",
    "        prompt_modelB_textbox.insert(\"end\",model_API + response.choices[0].text)\n",
    "    #print(response.choices[0].text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_a_function(temperature=0.5,prefix=\"Write a function that checks if a year is a leap year.\") -> object:\n",
    "    \"\"\"Example of using Code Generation to write a function.\"\"\"\n",
    "\n",
    "    # TODO developer - override these parameters as needed:\n",
    "    parameters = {\n",
    "        \"temperature\": temperature,  # Temperature controls the degree of randomness in token selection.\n",
    "        \"max_output_tokens\": 256,  # Token limit determines the maximum amount of text output.\n",
    "    }\n",
    "\n",
    "    code_generation_model = CodeGenerationModel.from_pretrained(\"code-bison@001\")\n",
    "    response = code_generation_model.predict(\n",
    "        prefix=prefix, **parameters\n",
    "    )\n",
    "\n",
    "    print(f\"Response from Model: {response.text}\")\n",
    "    # [END aiplatform_sdk_code_generation_function]\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model_StarChat(code):\n",
    "    \n",
    "    model_API = \"# StarChat\\n\"\n",
    "    print(\"Model {code}:\")\n",
    "    starchat_body = {\n",
    "        \"prompt\":prompt_textbox.get(1.0, \"end-1c\")\n",
    "        }\n",
    "    starchat_response = requests.post(starchat_URL, json = starchat_body)\n",
    "    starchat_json = starchat_response.json()\n",
    "    print(starchat_json['body'])\n",
    "    if code == \"A\":\n",
    "        prompt_modelA_textbox.delete(\"1.0\",\"end\")\n",
    "        prompt_modelA_textbox.insert(\"end\",model_API + starchat_json['body'])\n",
    "    elif code == \"B\":\n",
    "        prompt_modelB_textbox.delete(\"1.0\",\"end\")\n",
    "        prompt_modelB_textbox.insert(\"end\",model_API + starchat_json['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_models():\n",
    "    \"\"\"change which lines are commented out to change which models are called in each box\"\"\"\n",
    "    call_model_OpenAI(\"A\")\n",
    "    #call_model_OpenAI(\"B\")\n",
    "    #call_model_StarChat(\"A\")\n",
    "    call_model_StarChat(\"B\")\n",
    "    #call_model_GCP(\"A\") ...WIP...\n",
    "    #call_model_GCP(\"B\") ...WIP...\n",
    "    root.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output():\n",
    "    output_file = open(\"output.txt\",\"w\")\n",
    "    choice_str = \"\"\n",
    "\n",
    "    if choice_var == 1:\n",
    "        choice_str = \"Model A is better\\n\"\n",
    "    elif choice_var == 2:\n",
    "        choice_str = \"Model B is better\\n\"\n",
    "    elif choice_var == 3:\n",
    "        choice_str = \"It's a tie\\n\"\n",
    "    elif choice_var == 4:\n",
    "        choice_str = \"Neither are good\\n\"\n",
    "    else:\n",
    "        choice_str = \"Defalt Choice\\n\"\n",
    "\n",
    "    write_str = \"Prompt:\\n\" + prompt_textbox.get(\"1.0\",\"end-1c\") + \"\\n\\n\" + \\\n",
    "                    \"Model A:\\n\" + prompt_modelA_textbox.get(\"1.0\",\"end-1c\") + \"\\n\\n\" + \\\n",
    "                    \"Model B:\\n\" + prompt_modelB_textbox.get(\"1.0\",\"end-1c\") + \"\\n\\n\" + \\\n",
    "                    \"Review:\\n\" + \\\n",
    "                    \"\" + choice_str + \\\n",
    "                    \"% Closer to the expected output:\\n\" +\\\n",
    "                    \"Model A: \" + expected2_textbox.get(\"1.0\",\"end-1c\") + \"%\\n\" + \\\n",
    "                    \"Model B: \" + expected3_textbox.get(\"1.0\",\"end-1c\") + \"%\\n\" + \\\n",
    "                    \"Aditional time needed:\\n\"+\\\n",
    "                    \"Model A: \" + time2_md_textBox.get(\"1.0\",\"end-1c\") + \" OR ...WIP...\\n\" + \\\n",
    "                    \"Model B: \" + time3_md_textBox.get(\"1.0\",\"end-1c\") + \" OR ...WIP...\\n\" + \\\n",
    "                    \"Optimization criteria:\\n\"+\\\n",
    "                    \"Model A: \" + o_response1_textbox.get(\"1.0\",\"end-1c\") + \"\\n\" + \\\n",
    "                    \"Model B: \" + o_response2_textbox.get(\"1.0\",\"end-1c\") + \"\\n\" + \\\n",
    "                    \"Extra comments:\\n\"+\\\n",
    "                    \"Model A: \" + s_response1_textbox.get(\"1.0\",\"end-1c\") + \"\\n\" + \\\n",
    "                    \"Model B: \" + s_response2_textbox.get(\"1.0\",\"end-1c\") + \"\\n\" + \\\n",
    "                    \"...\"\n",
    "\n",
    "                \n",
    "    output_file.write(write_str)\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_click():\n",
    "    print(\"Choice:\",choice_var.get())\n",
    "    if choice_var.get() == 0:\n",
    "        print(\"Make a selection\")\n",
    "        save_response_button.config(bg='thistle2',state='disabled')\n",
    "    else:\n",
    "        write_output()\n",
    "        save_response_button.config(bg='light blue',text=\"Saved\",state='disabled')\n",
    "    root.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_click():\n",
    "    print(\"Choice:\",choice_var.get())\n",
    "    if choice_var.get() == 0:\n",
    "        print(\"Make a selection\")\n",
    "        save_response_button.config(bg='thistle2',text=save_default_str,state='disabled')\n",
    "    else:\n",
    "        save_response_button.config(bg='light green',text=save_default_str,state='active')\n",
    "    root.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model {code}:\n",
      "API KEY:  147fa51fedb346babf30e8e91b0ad8e5\n",
      "Model {code}:\n",
      "\n",
      "Here is an example of Python code that merges two dataframes based on a common column:\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Load the two dataframes\n",
      "df1 = pd.read_csv('dataframe1.csv')\n",
      "df2 = pd.read_csv('dataframe2.csv')\n",
      "\n",
      "# Merge the dataframes based on a common column\n",
      "merged_df = pd.merge(df1, df2, on='common_column')\n",
      "\n",
      "# Save the merged dataframe to a CSV file\n",
      "merged_df.to_csv('merged_dataframe.csv', index=False)\n",
      "\n",
      "In this example, the dataframes df1 and df2 are loaded using the Pandas read_csv function, and then merged using the Pandas merge function. The on parameter specifies the common column on which to merge the dataframes. The merged dataframe is then saved to a CSV file using the to_csv function.\n"
     ]
    }
   ],
   "source": [
    "root: Tk = Tk()\n",
    "root.title(\"GenAI Comparison Testing\")\n",
    "screen_width: int = root.winfo_screenwidth()\n",
    "screen_height: int = root.winfo_screenheight()\n",
    "root.geometry(\"%dx%d\" % (screen_width, screen_height))\n",
    "\n",
    "root.configure(background='#fff')\n",
    "\n",
    "#background_image_src = Image.open('bg_grad_purple_blue.png')\n",
    "#background_image = ImageTk.PhotoImage(background_image_src)\n",
    "button_bg_image_src = Image.open('button_bg1.png')\n",
    "button_bg_image = ImageTk.PhotoImage(button_bg_image_src)\n",
    "\n",
    "#background_image_label = Label(root,image=background_image)\n",
    "#background_image_label.place(x=0,y=0,width=screen_width,height=screen_height)\n",
    "\n",
    "#String Variables\n",
    "hours_arr = range(0,23)\n",
    "minutes_arr = range(0,59)\n",
    "hours_str_arr = []\n",
    "minutes_str_arr = []\n",
    "for i in hours_arr: \n",
    "    hours_str_arr.append(str(i))\n",
    "for i in minutes_arr: \n",
    "    minutes_str_arr.append(str(i))\n",
    "time2_hrs_var: StringVar = StringVar(root)\n",
    "time2_hrs_var.set('0')\n",
    "time2_min_var: StringVar = StringVar(root)\n",
    "time2_min_var.set('0')\n",
    "time3_hrs_var: StringVar = StringVar(root)\n",
    "time3_hrs_var.set('0')\n",
    "time3_min_var: StringVar = StringVar(root)\n",
    "time3_min_var.set('0')\n",
    "prompt_var: StringVar = StringVar(root)\n",
    "default_prompt_message = \"generate python code to merge two dataframes\"\n",
    "prompt_var.set(default_prompt_message)\n",
    "\n",
    "# Intager Variables\n",
    "choice_var = IntVar()\n",
    "choice_var.set(0)\n",
    "\n",
    "#Prompt Master Frame\n",
    "#prompt_master_frame = Frame(root,highlightbackground=\"orange\", highlightthickness=2,background='#fff')\n",
    "prompt_master_frame = Frame(root,background='#fff')\n",
    "prompt_master_frame.grid(column=0,row=0,sticky=N,padx=2)\n",
    "\n",
    "#Prompt Text Frame\n",
    "prompt_text_frame = Frame(prompt_master_frame,background='#fff')\n",
    "prompt_text_frame.grid(column=0,row=0)\n",
    "prompt_title_label = Label(prompt_text_frame, text=\"Prompt the models\",font=title_font,bg='#fff')\n",
    "prompt_title_label.grid(column=0,row=0)\n",
    "prompt_sub_label = Label(prompt_text_frame,justify=LEFT,text=\"For the given task above, write a prompt in the prompt box below \\n\" +\\\n",
    "                         \"to generate outputs from both of the Models A and B.\",bg='#fff')\n",
    "prompt_sub_label.grid(column=0,row=1)\n",
    "\n",
    "#Prompt Entry Labels\n",
    "text_width = 25\n",
    "text_height = 20\n",
    "prompt_width = int((text_height * 2.5) + 2)\n",
    "prompt_height = text_height / 4\n",
    "prompt_entry_frame = Frame(prompt_master_frame,background='#fff')\n",
    "prompt_entry_frame.grid(column=0,row=1,padx=5,pady=5)\n",
    "prompt_modelA_label = Label(prompt_entry_frame,text=\"Model A\",bg='#fff')\n",
    "prompt_modelA_label.grid(column=0,row=0)\n",
    "prompt_modelB_label = Label(prompt_entry_frame,text=\"Model B\",bg='#fff')\n",
    "prompt_modelB_label.grid(column=1,row=0)\n",
    "prompt_modelA_textbox = Text(prompt_entry_frame,width=text_width,height=text_height,highlightbackground='#888', highlightthickness=1)\n",
    "prompt_modelA_textbox.grid(column=0,row=1,padx=5,pady=5)\n",
    "prompt_modelB_textbox = Text(prompt_entry_frame,width=text_width,height=text_height,highlightbackground='#888', highlightthickness=1)\n",
    "prompt_modelB_textbox.grid(column=1,row=1,padx=5,pady=5)\n",
    "prompt_modelA_copybutton = Button(prompt_entry_frame,text=\"Write A\",command=write_model_A,background='LightSkyBlue1',borderwidth=0)\n",
    "prompt_modelA_copybutton.grid(column=0,row=2,padx=5,pady=5)\n",
    "prompt_modelB_copybutton = Button(prompt_entry_frame,text=\"Write B\",command=write_model_B,background='LightSkyBlue1',borderwidth=0)\n",
    "prompt_modelB_copybutton.grid(column=1,row=2,padx=5,pady=5)\n",
    "prompt_textbox = Text(prompt_entry_frame,width=prompt_width,height=prompt_height,highlightbackground='#888', highlightthickness=1)\n",
    "prompt_textbox.grid(column=0,row=3,pady=15,columnspan=2)\n",
    "prompt_textbox.delete(\"1.0\",\"end\")\n",
    "prompt_textbox.insert(\"end\",default_prompt_message)\n",
    "# Submit Prompt Button\n",
    "submit_button_frame = Frame(prompt_entry_frame,background='#fff')\n",
    "submit_button_frame.grid(column=0,row=4,columnspan=2,sticky=E,padx=5,pady=2)\n",
    "refresh_button = Button(submit_button_frame,text=\"Refresh\",command=refresh_root,width=8,height=1,background='#ddf',borderwidth=0)\n",
    "refresh_button.grid(column=0,row=0,sticky=E)\n",
    "submit_button = Button(submit_button_frame,text=\"Submit\",command=call_models,width=8,height=1,background='light green',borderwidth=0)\n",
    "submit_button.grid(column=1,row=0,sticky=E)\n",
    "\n",
    "\n",
    "root_separator = ttk.Separator(root,orient=VERTICAL)\n",
    "root_separator.grid(column=1,row=0,sticky=NS)\n",
    "\n",
    "# Question Frame\n",
    "question_master_frame = Frame(root,background='#fff')\n",
    "question_master_frame.grid(column=2,row=0,padx=5,sticky=N)\n",
    "\n",
    "question_header_frame = Frame(question_master_frame,background='#fff')\n",
    "question_header_frame.grid(column=0,row=0,padx=5)\n",
    "\n",
    "question_header_label = Label(question_header_frame,text=\"Answer the following questions\",bg='#fff',font=title_font)\n",
    "question_header_label.grid(column=0,row=0)\n",
    "question_sub_label = Label(question_header_frame,text=\"Which models' output buality is better?*\",bg='#fff')\n",
    "question_sub_label.grid(column=0,row=1)\n",
    "\n",
    "# Choice Frame\n",
    "question_choice_frame = Frame(question_master_frame,background='#fff')\n",
    "question_choice_frame.grid(column=0,row=2)\n",
    "\n",
    "option1_rb = Radiobutton(question_choice_frame, text=\"Model A is better\",variable=choice_var,value=1,command=lambda: [SEL,check_click()],bg='#fff')\n",
    "option1_rb.grid(column=0,row=0)\n",
    "option2_rb = Radiobutton(question_choice_frame, text=\"Model B is better\",variable=choice_var,value=2,command=lambda: [SEL,check_click()],bg='#fff')\n",
    "option2_rb.grid(column=1,row=0)\n",
    "option3_rb = Radiobutton(question_choice_frame, text=\"It's a tie\",variable=choice_var,value=3,command=lambda: [SEL,check_click()],bg='#fff')\n",
    "option3_rb.grid(column=2,row=0)\n",
    "option4_rb = Radiobutton(question_choice_frame, text=\"Neither are good\",variable=choice_var,value=4,command=lambda: [SEL,check_click()],bg='#fff')\n",
    "option4_rb.grid(column=3,row=0)\n",
    "\n",
    "# Question Detail Frame\n",
    "question_detail_frame = Frame(question_master_frame,highlightbackground=\"#888\", highlightthickness=1,background='#fff')\n",
    "question_detail_frame.grid(column=0,row=3,padx=2,sticky=EW)\n",
    "\n",
    "detail_header_padx = 10\n",
    "detail_header_pady = 5\n",
    "detail_header1_label = Label(question_detail_frame, text=\"       \",bg='#fff',font=title_font)\n",
    "detail_header1_label.grid(column=0,row=0,padx=detail_header_padx,pady=detail_header_pady)\n",
    "vertical1_seperator = ttk.Separator(question_detail_frame,orient=VERTICAL)\n",
    "vertical1_seperator.grid(column=1,row=0,rowspan=5,sticky=NS)\n",
    "detail_header2_label = Label(question_detail_frame, text=\"Model A\",bg='#fff',font=title_font)\n",
    "detail_header2_label.grid(column=2,row=0,padx=detail_header_padx,pady=detail_header_pady)\n",
    "vertical2_seperator = ttk.Separator(question_detail_frame,orient=VERTICAL)\n",
    "vertical2_seperator.grid(column=3,row=0,rowspan=5,sticky=NS)\n",
    "detail_header3_label = Label(question_detail_frame, text=\"Model B\",bg='#fff',font=title_font)\n",
    "detail_header3_label.grid(column=4,row=0,padx=detail_header_padx,pady=detail_header_pady)\n",
    "detail_header_seperator = ttk.Separator(question_detail_frame,orient=HORIZONTAL)\n",
    "detail_header_seperator.grid(column=0,row=1,columnspan=5,sticky=EW)\n",
    "\n",
    "expected1_frame = Frame(question_detail_frame,background='#fff')\n",
    "expected1_frame.grid(column=0,row=2,padx=2,sticky=NW)\n",
    "expected1_header_label = Label(expected1_frame,anchor='w',text=\"% Closer to the expected output\",bg='#fff')\n",
    "expected1_header_label.grid(column=0,row=0,padx=2,sticky=W)\n",
    "expected1_sub_label = Label(expected1_frame,justify=LEFT,text=\"Both models have generated outputs based on your prompts.\\n\" + \\\n",
    "                        \"How close are the outputs to the expected output?\\n\" + \\\n",
    "                        \"Enter in %.\",bg='#fff')\n",
    "expected1_sub_label.grid(column=0,row=1,padx=2,sticky=W)\n",
    "\n",
    "percentage_width = 12\n",
    "\n",
    "expected2_frame = Frame(question_detail_frame,background='#fff')\n",
    "expected2_frame.grid(column=2,row=2,padx=2,sticky=N)\n",
    "expected2_header_label = Label(expected2_frame,text=\"Percentage*\",bg='#fff')\n",
    "expected2_header_label.grid(column=0,row=0,padx=2)\n",
    "expected2_textbox = Text(expected2_frame,width=percentage_width,height=1,highlightbackground='#888', highlightthickness=1)\n",
    "expected2_textbox.grid(column=0,row=1,padx=2)\n",
    "\n",
    "expected3_frame = Frame(question_detail_frame,background='#fff')\n",
    "expected3_frame.grid(column=4,row=2,padx=2,sticky=N)\n",
    "expected3_header_label = Label(expected3_frame,text=\"Percentage*\",bg='#fff')\n",
    "expected3_header_label.grid(column=0,row=0,padx=2)\n",
    "expected3_textbox = Text(expected3_frame,width=percentage_width,height=1,highlightbackground='#888', highlightthickness=1)\n",
    "expected3_textbox.grid(column=0,row=1,padx=2)\n",
    "expected_seperator = ttk.Separator(question_detail_frame,orient=HORIZONTAL)\n",
    "expected_seperator.grid(column=0,row=3,columnspan=5,sticky=EW)\n",
    "\n",
    "time1_frame = Frame(question_detail_frame,background='#fff')\n",
    "time1_frame.grid(column=0,row=4,padx=2,sticky=NW)\n",
    "time1_header_label = Label(time1_frame,justify=LEFT,text=\"Time needed to be spent on improving the generated output\",bg='#fff')\n",
    "time1_header_label.grid(column=0,row=0,padx=2,sticky=W)\n",
    "time1_sub_label = Label(time1_frame,justify=LEFT,text=\"How much time would you\\n\" + \\\n",
    "                        \"have to spend to modify the model generated\\n\" + \\\n",
    "                        \"outputs to match your expected output?\",bg='#fff')\n",
    "time1_sub_label.grid(column=0,row=1,padx=2,sticky=W)\n",
    "\n",
    "time2_frame = Frame(question_detail_frame,background='#fff')\n",
    "time2_frame.grid(column=2,row=4,padx=2,sticky=N)\n",
    "time2_md_label = Label(time2_frame,text=\"Man Days*\",bg='#fff')\n",
    "time2_md_label.grid(column=0,row=0,padx=1)\n",
    "time2_md_textBox = Text(time2_frame,width=5,height=1,highlightbackground='#888', highlightthickness=1)\n",
    "time2_md_textBox.grid(column=0,row=1,padx=2)\n",
    "time2_or_label = Label(time2_frame,text=\"OR \",bg='#fff')\n",
    "time2_or_label.grid(column=1,row=1)\n",
    "time2_hrs_label = Label(time2_frame,text=\"Hrs*\",bg='#fff')\n",
    "time2_hrs_label.grid(column=2,row=0,padx=2)\n",
    "time2_hrs_opt = ttk.Combobox(time2_frame, textvariable=time2_hrs_var, values=hours_str_arr,width=5)\n",
    "time2_hrs_opt.grid(column=2,row=1,padx=2)\n",
    "time2_min_label = Label(time2_frame,text=\"Min*\",bg='#fff')\n",
    "time2_min_label.grid(column=3,row=0,padx=2)\n",
    "time2_min_opt = ttk.Combobox(time2_frame, textvariable=time2_min_var, values=minutes_str_arr,width=5)\n",
    "time2_min_opt.grid(column=3,row=1,padx=2)\n",
    "\n",
    "time3_frame = Frame(question_detail_frame,background='#fff')\n",
    "time3_frame.grid(column=4,row=4,padx=2,sticky=N)\n",
    "time3_md_label = Label(time3_frame,text=\"Man Days*\",bg='#fff')\n",
    "time3_md_label.grid(column=0,row=0,padx=1)\n",
    "time3_md_textBox = Text(time3_frame,width=5,height=1,highlightbackground='#888', highlightthickness=1)\n",
    "time3_md_textBox.grid(column=0,row=1,padx=2)\n",
    "time3_or_label = Label(time3_frame,text=\"OR \",bg='#fff')\n",
    "time3_or_label.grid(column=1,row=1)\n",
    "time3_hrs_label = Label(time3_frame,text=\"Hrs*\",bg='#fff')\n",
    "time3_hrs_label.grid(column=2,row=0,padx=2)\n",
    "time3_hrs_opt = ttk.Combobox(time3_frame, textvariable=time3_hrs_var, values=hours_str_arr,width=5)\n",
    "time3_hrs_opt.grid(column=2,row=1,padx=2)\n",
    "time3_min_label = Label(time3_frame,text=\"Min*\",bg='#fff')\n",
    "time3_min_label.grid(column=3,row=0,padx=2)\n",
    "time3_min_opt = ttk.Combobox(time3_frame, textvariable=time3_min_var, values=minutes_str_arr,width=5)\n",
    "time3_min_opt.grid(column=3,row=1,padx=2)\n",
    "\n",
    "# Optomize Frame\n",
    "optomize_master_frame = Frame(question_master_frame,background='#fff')\n",
    "optomize_master_frame.grid(column=0,row=4,padx=2)\n",
    "optomize_header_label = Label(optomize_master_frame,font=title_font,text=\"What criteria do you need to optimize the outputs for?*\",bg='#fff')\n",
    "optomize_header_label.grid(column=0,row=0,pady=2)\n",
    "optomize_sub_label = Label(optomize_master_frame,text=\"For each model, can you list the areas where the outputs need to\\n\" +\\\n",
    "                        \"be optimized further? List at least one point each.\",bg='#fff')\n",
    "optomize_sub_label.grid(column=0,row=1,pady=2)\n",
    "optomize_response_frame = Frame(optomize_master_frame,background='#fff')\n",
    "optomize_response_frame.grid(column=0,row=2,padx=5,pady=5)\n",
    "response_width = 30\n",
    "response_height = 3\n",
    "o_response1_label = Label(optomize_response_frame,text=\"Model A*\",bg='#fff')\n",
    "o_response1_label.grid(column=0,row=0,padx=5,pady=3)\n",
    "o_response1_textbox = Text(optomize_response_frame,width=response_width,height=response_height,highlightbackground='#888', highlightthickness=1)\n",
    "o_response1_textbox.grid(column=0,row=1,padx=2,pady=2)\n",
    "o_response2_label = Label(optomize_response_frame,text=\"Model B*\",bg='#fff')\n",
    "o_response2_label.grid(column=1,row=0,padx=5,pady=3)\n",
    "o_response2_textbox = Text(optomize_response_frame,width=response_width,height=response_height,highlightbackground='#888', highlightthickness=1)\n",
    "o_response2_textbox.grid(column=1,row=1,padx=2,pady=2)\n",
    "\n",
    "# Standards Frame\n",
    "standards_master_frame = Frame(question_master_frame,background='#fff')\n",
    "standards_master_frame.grid(column=0,row=5,padx=2)\n",
    "standards_header_label = Label(standards_master_frame,font=title_font,text=\"Extra comments?\",bg='#fff')\n",
    "standards_header_label.grid(column=0,row=0,pady=2)\n",
    "#standards_sub_label = Label(standards_master_frame,text=\"Can you list for each model the areas on which the outputs need to\\n\" +\\\n",
    "#                        \"be optimized further for it to be as you envision. List at least one point each.r\",bg='#fff')\n",
    "#standards_sub_label.grid(column=0,row=1,pady=2)\n",
    "standards_response_frame = Frame(standards_master_frame,background='#fff')\n",
    "standards_response_frame.grid(column=0,row=1,padx=5,pady=5)\n",
    "response_width = 30\n",
    "response_height = 3\n",
    "s_response1_label = Label(standards_response_frame,text=\"Model A\",bg='#fff')\n",
    "s_response1_label.grid(column=0,row=0,padx=5,pady=3)\n",
    "s_response1_textbox = Text(standards_response_frame,width=response_width,height=response_height,highlightbackground='#888', highlightthickness=1)\n",
    "s_response1_textbox.grid(column=0,row=1,padx=2,pady=2)\n",
    "s_response2_label = Label(standards_response_frame,text=\"Model B\",bg='#fff')\n",
    "s_response2_label.grid(column=1,row=0,padx=5,pady=3)\n",
    "s_response2_textbox = Text(standards_response_frame,width=response_width,height=response_height,highlightbackground='#888', highlightthickness=1)\n",
    "s_response2_textbox.grid(column=1,row=1,padx=2,pady=2)\n",
    "\n",
    "save_response_button = Button(question_master_frame,text=save_default_str,command=save_click,background='thistle2',borderwidth=0,state='disabled')\n",
    "save_response_button.grid(column=0,row=6,padx=2,ipadx=5)\n",
    "\n",
    "root.lift()\n",
    "#root.attributes('-topmost', True)\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
